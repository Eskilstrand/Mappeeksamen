{"title":"Å trekke slutninger fra statistiske modeller og statistisk styrke","markdown":{"yaml":{"title":"Å trekke slutninger fra statistiske modeller og statistisk styrke","editor_options":{"chunk_output_type":"console"},"geometry":["top=0.5in","bottom=0.5in","left=1in","right=1in"]},"headingText":"Spørsmål og svar","containsRefs":false,"markdown":"\n\n\n\n```{r}\n#| echo: false\n#| label: \"Standardscript for pakker\"\n#| warning: false\n#| message: false\n\n\nlibrary(readxl)\nlibrary(tidyr)\nlibrary(exscidata)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(gt)\nlibrary(ggtext)\nlibrary(pwr)\n\n\n```\n\n\n\n\n```{r}\n#| echo: false\n\n\n\n\nset.seed(1)\npopulation <- rnorm(1000000, mean = 1.5, sd = 3)\n\nsamp1 <- data.frame(y = sample(population, 8, replace = FALSE))\nsamp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\nm1 <- lm(y ~ 1, data = samp1)\nm2 <- lm(y ~ 1, data = samp2)\n\n# Skjul summary-output\ninvisible(summary(m1))\ninvisible(summary(m2))\n\n\n\n\n\n```\n\n\n\n### Estimate \n\nEt **estimat** er en verdi vi får ved å anvende en lineær modell på våre data. Dette tallet representerer vår beste gjetning av den sanne verdien til parameteren vi ønsker å estimere i populasjonen, basert på vårt utvalg. I konteksten av en regresjonsanalyse er dette ofte regresjonskoeffisienten, som estimerer sammenhengen mellom en uavhengig variabel og den avhengige variabelen *y*.\n\n**Standardfeilen** (SE) kvantifiserer usikkerheten knyttet til estimatet vårt. Den måler den forventede variasjonen i estimatet dersom vi skulle trekke mange utvalg fra populasjonen og beregne estimatet hver gang. Med andre ord er standardfeilen standardavviket til estimatets utvalgsfordeling, og indikerer hvor mye estimatet vårt potensielt kan variere fra utvalg til utvalg på grunn av tilfeldig sampling.\n\n**t-verdien** er forholdet mellom estimatet og standardfeilen ($t = \\frac{{estimat}}{{SE}}$). Den indikerer hvor mange standardfeil estimatet er unna null [@Spiegelhalter]. En høy absolutt t-verdi tyder på at estimatet er signifikant forskjellig fra null.\n\n**P-verdien** angir sannsynligheten for å observere en t-verdi som er minst like ekstrem som den vi har fått, gitt at nullhypotesen er sann. Det vil si, den måler sannsynligheten for å få våre data, eller data som er mer ekstreme, dersom det faktisk ikke er noen effekt (dvs. hvis den sanne parameteren er null). En lav p-verdi indikerer at et så ekstremt resultat er lite sannsynlig under nullhypotesen, noe som gir grunnlag for å forkaste nullhypotesen [@Spiegelhalter].\n\nI vårt tilfelle har vi en høy p-verdi, noe som indikerer at vi ikke kan forkaste nullhypotesen. Dette betyr at det ikke er tilstrekkelig bevis til å konkludere med at det er en signifikant forskjell fra null.\n\n### m1 vs m2\n\nForskjellen mellom studiene kommer fra størrelsen på utvalget som er brukt i de to forskjellige. I *m1* er det brukt ett mye mindre utvalg, noe som fører til større usikkerhet rundt resultatene. I *m2* er det brukt et større utvalg, som gjør at det estimerte gjennomsnittet blir nærmere populasjonsgjennomsnittet og standardfeilen blir dermed mindre. Dette gir i vårt tilfelle en høyere **t-verdi** og en lavere **p-verdi** [@Spiegelhalter].\n\n### Shaded areas\nVi bruker de grå feltene for å vise de ekstreme verdiene vi har fra testen vår. Jo lenger ut i halene vi kommer, desto større sannsynlighet er det for at dette er et uvanlig resultat å se. \n\n\n```{r}\n#| code-fold: true\n#| message: false\n#| warning: false\n\n# Create data frames to store the model estimates\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample\n# from the population. \n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n# Save the results in a combined data frame\n\nresults <- bind_rows(results_8, results_40)\n\n# Calculate standard deviation of the estimate and the average of the standard error (se)\nresults_summary <- results |> \n  group_by(n) |> \n  summarise(\n    sd_estimate = sd(estimate),\n    avg_se = mean(se)\n  )\n\n\nsd_est_8 <- sd(results$estimate[results$n == 8])\navg_se_8 <- mean(results$se[results$n == 8])\n\nsd_est_40 <- sd(results$estimate[results$n == 40])\navg_se_40 <- mean(results$se[results$n == 40])\n\nrounded_sd_est_8 <- round(sd_est_8, 2)\nrounded_avg_se_8 <- round(avg_se_8, 2)\nrounded_sd_est_40 <- round(sd_est_40, 2)\nrounded_avg_se_40 <- round(avg_se_40, 2)\n\n\n```\n\n### Standard deviation of **estimate** and avg. **se** for each study. \n\nStandard deviation for modellen med 8 i population er `r rounded_sd_est_8`, mens det for modellen med 40 i population er `r rounded_sd_est_40`. Når det kommer til gjennomsnittlig standardfeil ligger den på `r rounded_avg_se_8` for modellen med 8 i population, mens den for modellen med 40 i population ligger på `r rounded_avg_se_40`. Grunnen til at tallene er såpass like som de er for **SD** og **avg se** er at begge beregningene er mål på variasjon. I denne sammenhengen er standardfeilen et mål på hvor mye gjennomsnittet avviker fra det sanne populasjonsgjennomsnittet. \n\n\n### P-value histogram\n\n```{r}\n#| code-fold: true\n#| label: \"P-verdi histogram SS8\"\n\nggplot(results[results$n == 8, ], aes(x = pval)) +\n  geom_histogram(binwidth = 0.05, fill = \"green\", alpha = 0.6) +\n  labs(title = \"P-verdier fordeling til samplesize 8\",\n       x = \"P-verdier\",\n       y = \"frekvens\") +\n  theme_minimal()\n\n\n```\n\nNår vi ser histogrammet for modellen med utvalgsstørrelse på 8, ser vi tydelig at det er mange observasjoner av høye p-verdier. Dette gjenspeiler den lave statistiske poweren vi får av å gjøre studier med en så liten utvalgsstørrelse. \n\n\n\n```{r}\n#| code-fold: true\n#| label: \"P-verdi histogram SS40\"\n\nggplot(results[results$n == 40, ], aes(x = pval)) +\n  geom_histogram(binwidth = 0.05, fill = \"green\", alpha = 0.6) +\n  labs(title = \"P-verdier fordeling til samplesize 40\",\n       x = \"P-verdier\",\n       y = \"frekvens\") +\n  theme_classic()\n\n\n\n\n```\n\nPå histogrammet med utvalgsstørrelse på 40 ser vi at det er en mye større samling av observasjoner på lave p-verdier. Dette gjenspeiler det vi vet om at en større utvalgsstørrelse gir en større statistisk power. \n\n\n### Antall studier med statistisk signifikans\n\n\n```{r}\n#| code-fold: true\n#| label: \"Calculate number of studies with stat signif\"\n\nalpha <- 0.05\n\nsignificant_8 <- sum(results$pval[results$n == 8] < alpha)\nsignificant_40 <- sum(results$pval[results$n == 40] < alpha)\n\n\n\n\n```\n\nI studiene med utvalgsstørrelse på 8 ser vi at det er `r significant_8` studier som viser statistisk signifikans, mens det i studiene med utvalgsstørrelse på 40 er hele `r significant_40` studier som viser statistisk signifikans. Dette gir et godt bilde på hvor mye utvalgsstørrelsen har å si for resultatet i utregningen vår. I mitt tilfelle har jeg valgt å sette terskelen for signifikans (p-verdi) til `r alpha`.\n\n\n### Power of a one-sample t-test\n\n```{r}\n#| code-fold: true\n#| label: \"Utregning av stat power\"\n\neffect_size <- 1.5 / 3\n\npower_8 <- pwr.t.test(n = 8,\n                      d = effect_size,\n                      sig.level = alpha,\n                      type = \"one.sample\")$power\nrounded_power_8 <- round(power_8, 3)\n\n\npower_40 <- pwr.t.test(n = 40,\n                       d = effect_size,\n                       sig.level = alpha,\n                       type = \"one.sample\")$power\n\nrounded_power_40 <- round(power_40, 3)\n\nrounded_power_40_perc <- rounded_power_40 * 100\n\n\n\n\n```\n\nNår vi gjennomfører utregningen ser vi at studiene med lav utvalgsstørrelse (8) får en mye lavere statistisk styrke (`r rounded_power_8`) enn studiene med utvalgsstørrelse på 40 (`r rounded_power_40`). Svarene vi får av disse utregningene støtter det vi tidligere har funnet ut, at dersom vi har et større utvalg, er det større sannsynlighet for at vi ser en faktisk effekt, og at det ikke er en tilfeldighet at vi har funnet det vi har i studien. I dette tilfelle vil vi da få en `r rounded_power_40_perc`% sjanse for å oppdage en sann effekt. \n\n\n### Med signifikansnivå på 0.05 hvor mange studier gir \"falsk positiv\" ved gjennomføring av mange repeterte studier?\n\n```{r}\n#| code-fold: true\n#| label: \"Siste oppgave\"\n\n\nset.seed(1)\npopulation <- rnorm(1000000, mean = 0, sd = 3)\n\n\n# Create data frames to store the model estimates\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample\n# from the population. \n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n# Save the results in a combined data frame\n\nresults_null <- bind_rows(results_8, results_40)\n\n\n```\n\n\n```{r}\n#| code-fold: true\n#| label: \"Falske positive\"\n\n\nfalse_positive_8 <- sum(results_8$pval < 0.05)\nfalse_positive_40 <- sum(results_40$pval < 0.05)\n\n\nfalse_positive_8_alpha0.025 <- sum(results_8$pval < 0.025)\nfalse_positive_40_alpha0.025 <- sum(results_40$pval < 0.025)\n\n```\n\nVed å gjøre 1000 repeterte studier, vil vi få omtrent 50 falske positive hvis vi setter signifikansnivået til 0.05. I min utregning fikk jeg da `r false_positive_8` for studiene med utvalgsstørrelse på 8 og `r false_positive_40` på studiene med utvalgsstørrelse 40. Om jeg endrer signifikansnivået og setter alpha enda lavere vil resultatet endre seg litt. Med en signifikansverdi på 0.025 vil det i studiene med utvalgsstørrelse 8 gi meg `r false_positive_8_alpha0.025` falske positive, mens det på studiene med 40 i utvalgsstørrelse gir `r false_positive_40_alpha0.025` falske positive. \n\n\n\n## Code-chunks fra topp til bunn\n\n```{r}\n#| echo: true\n#| label: Kode 1\n\nset.seed(1)\npopulation <- rnorm(1000000, mean = 1.5, sd = 3)\n\nsamp1 <- data.frame(y = sample(population, 8, replace = FALSE))\nsamp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\nm1 <- lm(y ~ 1, data = samp1)\nm2 <- lm(y ~ 1, data = samp2)\n\n# Skjul summary-output\ninvisible(summary(m1))\ninvisible(summary(m2))\n\n\n```\n\n\n```{r}\n#| echo: true\n#| label: Kode 2\n\n# Create data frames to store the model estimates\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample\n# from the population. \n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n# Save the results in a combined data frame\n\nresults <- bind_rows(results_8, results_40)\n\n# Calculate standard deviation of the estimate and the average of the standard error (se)\nresults_summary <- results |> \n  group_by(n) |> \n  summarise(\n    sd_estimate = sd(estimate),\n    avg_se = mean(se)\n  )\n\n\nsd_est_8 <- sd(results$estimate[results$n == 8])\navg_se_8 <- mean(results$se[results$n == 8])\n\nsd_est_40 <- sd(results$estimate[results$n == 40])\navg_se_40 <- mean(results$se[results$n == 40])\n\nrounded_sd_est_8 <- round(sd_est_8, 2)\nrounded_avg_se_8 <- round(avg_se_8, 2)\nrounded_sd_est_40 <- round(sd_est_40, 2)\nrounded_avg_se_40 <- round(avg_se_40, 2)\n\n```\n\n```{r}\n#| echo: true\n#| label: Kode 3\n\nggplot(results[results$n == 8, ], aes(x = pval)) +\n  geom_histogram(binwidth = 0.05, fill = \"green\", alpha = 0.6) +\n  labs(title = \"P-verdier fordeling til samplesize 8\",\n       x = \"P-verdier\",\n       y = \"frekvens\") +\n  theme_minimal()\n\n```\n\n```{r}\n#| echo: true\n#| label: Kode 4\n\nalpha <- 0.05\n\nsignificant_8 <- sum(results$pval[results$n == 8] < alpha)\nsignificant_40 <- sum(results$pval[results$n == 40] < alpha)\n\n```\n\n```{r}\n#| echo: true\n#| label: Kode 5\n\neffect_size <- 1.5 / 3\n\npower_8 <- pwr.t.test(n = 8,\n                      d = effect_size,\n                      sig.level = alpha,\n                      type = \"one.sample\")$power\nrounded_power_8 <- round(power_8, 3)\n\n\npower_40 <- pwr.t.test(n = 40,\n                       d = effect_size,\n                       sig.level = alpha,\n                       type = \"one.sample\")$power\n\nrounded_power_40 <- round(power_40, 3)\n\nrounded_power_40_perc <- rounded_power_40 * 100\n\n\n\n```\n\n```{r}\n#| echo: true\n#| label: Kode 6\n\nset.seed(1)\npopulation <- rnorm(1000000, mean = 0, sd = 3)\n\n\n# Create data frames to store the model estimates\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample\n# from the population. \n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n# Save the results in a combined data frame\n\nresults_null <- bind_rows(results_8, results_40)\n\n\n```\n\n```{r}\n#| echo: true\n#| label: Kode 7\n\nfalse_positive_8 <- sum(results_8$pval < 0.05)\nfalse_positive_40 <- sum(results_40$pval < 0.05)\n\n\nfalse_positive_8_alpha0.025 <- sum(results_8$pval < 0.025)\nfalse_positive_40_alpha0.025 <- sum(results_40$pval < 0.025)\n\n```\n\n","srcMarkdownNoYaml":"\n\n\n\n```{r}\n#| echo: false\n#| label: \"Standardscript for pakker\"\n#| warning: false\n#| message: false\n\n\nlibrary(readxl)\nlibrary(tidyr)\nlibrary(exscidata)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(gt)\nlibrary(ggtext)\nlibrary(pwr)\n\n\n```\n\n\n## Spørsmål og svar\n\n\n```{r}\n#| echo: false\n\n\n\n\nset.seed(1)\npopulation <- rnorm(1000000, mean = 1.5, sd = 3)\n\nsamp1 <- data.frame(y = sample(population, 8, replace = FALSE))\nsamp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\nm1 <- lm(y ~ 1, data = samp1)\nm2 <- lm(y ~ 1, data = samp2)\n\n# Skjul summary-output\ninvisible(summary(m1))\ninvisible(summary(m2))\n\n\n\n\n\n```\n\n\n\n### Estimate \n\nEt **estimat** er en verdi vi får ved å anvende en lineær modell på våre data. Dette tallet representerer vår beste gjetning av den sanne verdien til parameteren vi ønsker å estimere i populasjonen, basert på vårt utvalg. I konteksten av en regresjonsanalyse er dette ofte regresjonskoeffisienten, som estimerer sammenhengen mellom en uavhengig variabel og den avhengige variabelen *y*.\n\n**Standardfeilen** (SE) kvantifiserer usikkerheten knyttet til estimatet vårt. Den måler den forventede variasjonen i estimatet dersom vi skulle trekke mange utvalg fra populasjonen og beregne estimatet hver gang. Med andre ord er standardfeilen standardavviket til estimatets utvalgsfordeling, og indikerer hvor mye estimatet vårt potensielt kan variere fra utvalg til utvalg på grunn av tilfeldig sampling.\n\n**t-verdien** er forholdet mellom estimatet og standardfeilen ($t = \\frac{{estimat}}{{SE}}$). Den indikerer hvor mange standardfeil estimatet er unna null [@Spiegelhalter]. En høy absolutt t-verdi tyder på at estimatet er signifikant forskjellig fra null.\n\n**P-verdien** angir sannsynligheten for å observere en t-verdi som er minst like ekstrem som den vi har fått, gitt at nullhypotesen er sann. Det vil si, den måler sannsynligheten for å få våre data, eller data som er mer ekstreme, dersom det faktisk ikke er noen effekt (dvs. hvis den sanne parameteren er null). En lav p-verdi indikerer at et så ekstremt resultat er lite sannsynlig under nullhypotesen, noe som gir grunnlag for å forkaste nullhypotesen [@Spiegelhalter].\n\nI vårt tilfelle har vi en høy p-verdi, noe som indikerer at vi ikke kan forkaste nullhypotesen. Dette betyr at det ikke er tilstrekkelig bevis til å konkludere med at det er en signifikant forskjell fra null.\n\n### m1 vs m2\n\nForskjellen mellom studiene kommer fra størrelsen på utvalget som er brukt i de to forskjellige. I *m1* er det brukt ett mye mindre utvalg, noe som fører til større usikkerhet rundt resultatene. I *m2* er det brukt et større utvalg, som gjør at det estimerte gjennomsnittet blir nærmere populasjonsgjennomsnittet og standardfeilen blir dermed mindre. Dette gir i vårt tilfelle en høyere **t-verdi** og en lavere **p-verdi** [@Spiegelhalter].\n\n### Shaded areas\nVi bruker de grå feltene for å vise de ekstreme verdiene vi har fra testen vår. Jo lenger ut i halene vi kommer, desto større sannsynlighet er det for at dette er et uvanlig resultat å se. \n\n\n```{r}\n#| code-fold: true\n#| message: false\n#| warning: false\n\n# Create data frames to store the model estimates\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample\n# from the population. \n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n# Save the results in a combined data frame\n\nresults <- bind_rows(results_8, results_40)\n\n# Calculate standard deviation of the estimate and the average of the standard error (se)\nresults_summary <- results |> \n  group_by(n) |> \n  summarise(\n    sd_estimate = sd(estimate),\n    avg_se = mean(se)\n  )\n\n\nsd_est_8 <- sd(results$estimate[results$n == 8])\navg_se_8 <- mean(results$se[results$n == 8])\n\nsd_est_40 <- sd(results$estimate[results$n == 40])\navg_se_40 <- mean(results$se[results$n == 40])\n\nrounded_sd_est_8 <- round(sd_est_8, 2)\nrounded_avg_se_8 <- round(avg_se_8, 2)\nrounded_sd_est_40 <- round(sd_est_40, 2)\nrounded_avg_se_40 <- round(avg_se_40, 2)\n\n\n```\n\n### Standard deviation of **estimate** and avg. **se** for each study. \n\nStandard deviation for modellen med 8 i population er `r rounded_sd_est_8`, mens det for modellen med 40 i population er `r rounded_sd_est_40`. Når det kommer til gjennomsnittlig standardfeil ligger den på `r rounded_avg_se_8` for modellen med 8 i population, mens den for modellen med 40 i population ligger på `r rounded_avg_se_40`. Grunnen til at tallene er såpass like som de er for **SD** og **avg se** er at begge beregningene er mål på variasjon. I denne sammenhengen er standardfeilen et mål på hvor mye gjennomsnittet avviker fra det sanne populasjonsgjennomsnittet. \n\n\n### P-value histogram\n\n```{r}\n#| code-fold: true\n#| label: \"P-verdi histogram SS8\"\n\nggplot(results[results$n == 8, ], aes(x = pval)) +\n  geom_histogram(binwidth = 0.05, fill = \"green\", alpha = 0.6) +\n  labs(title = \"P-verdier fordeling til samplesize 8\",\n       x = \"P-verdier\",\n       y = \"frekvens\") +\n  theme_minimal()\n\n\n```\n\nNår vi ser histogrammet for modellen med utvalgsstørrelse på 8, ser vi tydelig at det er mange observasjoner av høye p-verdier. Dette gjenspeiler den lave statistiske poweren vi får av å gjøre studier med en så liten utvalgsstørrelse. \n\n\n\n```{r}\n#| code-fold: true\n#| label: \"P-verdi histogram SS40\"\n\nggplot(results[results$n == 40, ], aes(x = pval)) +\n  geom_histogram(binwidth = 0.05, fill = \"green\", alpha = 0.6) +\n  labs(title = \"P-verdier fordeling til samplesize 40\",\n       x = \"P-verdier\",\n       y = \"frekvens\") +\n  theme_classic()\n\n\n\n\n```\n\nPå histogrammet med utvalgsstørrelse på 40 ser vi at det er en mye større samling av observasjoner på lave p-verdier. Dette gjenspeiler det vi vet om at en større utvalgsstørrelse gir en større statistisk power. \n\n\n### Antall studier med statistisk signifikans\n\n\n```{r}\n#| code-fold: true\n#| label: \"Calculate number of studies with stat signif\"\n\nalpha <- 0.05\n\nsignificant_8 <- sum(results$pval[results$n == 8] < alpha)\nsignificant_40 <- sum(results$pval[results$n == 40] < alpha)\n\n\n\n\n```\n\nI studiene med utvalgsstørrelse på 8 ser vi at det er `r significant_8` studier som viser statistisk signifikans, mens det i studiene med utvalgsstørrelse på 40 er hele `r significant_40` studier som viser statistisk signifikans. Dette gir et godt bilde på hvor mye utvalgsstørrelsen har å si for resultatet i utregningen vår. I mitt tilfelle har jeg valgt å sette terskelen for signifikans (p-verdi) til `r alpha`.\n\n\n### Power of a one-sample t-test\n\n```{r}\n#| code-fold: true\n#| label: \"Utregning av stat power\"\n\neffect_size <- 1.5 / 3\n\npower_8 <- pwr.t.test(n = 8,\n                      d = effect_size,\n                      sig.level = alpha,\n                      type = \"one.sample\")$power\nrounded_power_8 <- round(power_8, 3)\n\n\npower_40 <- pwr.t.test(n = 40,\n                       d = effect_size,\n                       sig.level = alpha,\n                       type = \"one.sample\")$power\n\nrounded_power_40 <- round(power_40, 3)\n\nrounded_power_40_perc <- rounded_power_40 * 100\n\n\n\n\n```\n\nNår vi gjennomfører utregningen ser vi at studiene med lav utvalgsstørrelse (8) får en mye lavere statistisk styrke (`r rounded_power_8`) enn studiene med utvalgsstørrelse på 40 (`r rounded_power_40`). Svarene vi får av disse utregningene støtter det vi tidligere har funnet ut, at dersom vi har et større utvalg, er det større sannsynlighet for at vi ser en faktisk effekt, og at det ikke er en tilfeldighet at vi har funnet det vi har i studien. I dette tilfelle vil vi da få en `r rounded_power_40_perc`% sjanse for å oppdage en sann effekt. \n\n\n### Med signifikansnivå på 0.05 hvor mange studier gir \"falsk positiv\" ved gjennomføring av mange repeterte studier?\n\n```{r}\n#| code-fold: true\n#| label: \"Siste oppgave\"\n\n\nset.seed(1)\npopulation <- rnorm(1000000, mean = 0, sd = 3)\n\n\n# Create data frames to store the model estimates\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample\n# from the population. \n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n# Save the results in a combined data frame\n\nresults_null <- bind_rows(results_8, results_40)\n\n\n```\n\n\n```{r}\n#| code-fold: true\n#| label: \"Falske positive\"\n\n\nfalse_positive_8 <- sum(results_8$pval < 0.05)\nfalse_positive_40 <- sum(results_40$pval < 0.05)\n\n\nfalse_positive_8_alpha0.025 <- sum(results_8$pval < 0.025)\nfalse_positive_40_alpha0.025 <- sum(results_40$pval < 0.025)\n\n```\n\nVed å gjøre 1000 repeterte studier, vil vi få omtrent 50 falske positive hvis vi setter signifikansnivået til 0.05. I min utregning fikk jeg da `r false_positive_8` for studiene med utvalgsstørrelse på 8 og `r false_positive_40` på studiene med utvalgsstørrelse 40. Om jeg endrer signifikansnivået og setter alpha enda lavere vil resultatet endre seg litt. Med en signifikansverdi på 0.025 vil det i studiene med utvalgsstørrelse 8 gi meg `r false_positive_8_alpha0.025` falske positive, mens det på studiene med 40 i utvalgsstørrelse gir `r false_positive_40_alpha0.025` falske positive. \n\n\n\n## Code-chunks fra topp til bunn\n\n```{r}\n#| echo: true\n#| label: Kode 1\n\nset.seed(1)\npopulation <- rnorm(1000000, mean = 1.5, sd = 3)\n\nsamp1 <- data.frame(y = sample(population, 8, replace = FALSE))\nsamp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\nm1 <- lm(y ~ 1, data = samp1)\nm2 <- lm(y ~ 1, data = samp2)\n\n# Skjul summary-output\ninvisible(summary(m1))\ninvisible(summary(m2))\n\n\n```\n\n\n```{r}\n#| echo: true\n#| label: Kode 2\n\n# Create data frames to store the model estimates\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample\n# from the population. \n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n# Save the results in a combined data frame\n\nresults <- bind_rows(results_8, results_40)\n\n# Calculate standard deviation of the estimate and the average of the standard error (se)\nresults_summary <- results |> \n  group_by(n) |> \n  summarise(\n    sd_estimate = sd(estimate),\n    avg_se = mean(se)\n  )\n\n\nsd_est_8 <- sd(results$estimate[results$n == 8])\navg_se_8 <- mean(results$se[results$n == 8])\n\nsd_est_40 <- sd(results$estimate[results$n == 40])\navg_se_40 <- mean(results$se[results$n == 40])\n\nrounded_sd_est_8 <- round(sd_est_8, 2)\nrounded_avg_se_8 <- round(avg_se_8, 2)\nrounded_sd_est_40 <- round(sd_est_40, 2)\nrounded_avg_se_40 <- round(avg_se_40, 2)\n\n```\n\n```{r}\n#| echo: true\n#| label: Kode 3\n\nggplot(results[results$n == 8, ], aes(x = pval)) +\n  geom_histogram(binwidth = 0.05, fill = \"green\", alpha = 0.6) +\n  labs(title = \"P-verdier fordeling til samplesize 8\",\n       x = \"P-verdier\",\n       y = \"frekvens\") +\n  theme_minimal()\n\n```\n\n```{r}\n#| echo: true\n#| label: Kode 4\n\nalpha <- 0.05\n\nsignificant_8 <- sum(results$pval[results$n == 8] < alpha)\nsignificant_40 <- sum(results$pval[results$n == 40] < alpha)\n\n```\n\n```{r}\n#| echo: true\n#| label: Kode 5\n\neffect_size <- 1.5 / 3\n\npower_8 <- pwr.t.test(n = 8,\n                      d = effect_size,\n                      sig.level = alpha,\n                      type = \"one.sample\")$power\nrounded_power_8 <- round(power_8, 3)\n\n\npower_40 <- pwr.t.test(n = 40,\n                       d = effect_size,\n                       sig.level = alpha,\n                       type = \"one.sample\")$power\n\nrounded_power_40 <- round(power_40, 3)\n\nrounded_power_40_perc <- rounded_power_40 * 100\n\n\n\n```\n\n```{r}\n#| echo: true\n#| label: Kode 6\n\nset.seed(1)\npopulation <- rnorm(1000000, mean = 0, sd = 3)\n\n\n# Create data frames to store the model estimates\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample\n# from the population. \n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n# Save the results in a combined data frame\n\nresults_null <- bind_rows(results_8, results_40)\n\n\n```\n\n```{r}\n#| echo: true\n#| label: Kode 7\n\nfalse_positive_8 <- sum(results_8$pval < 0.05)\nfalse_positive_40 <- sum(results_40$pval < 0.05)\n\n\nfalse_positive_8_alpha0.025 <- sum(results_8$pval < 0.025)\nfalse_positive_40_alpha0.025 <- sum(results_40$pval < 0.025)\n\n```\n\n"},"formats":{"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":true,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","include-in-header":{"text":"\\usepackage{amsmath}\n\\usepackage{float}\n\\usepackage{pdflscape}\n\\usepackage{afterpage}\n\\usepackage{longtable}\n\\usepackage[table]{xcolor}\n\\usepackage{longtable}\n\\usepackage{booktabs}\n\\usepackage{graphicx}\n\\usepackage{fontspec}\n\\setmainfont{Times New Roman}\n\\setsansfont{Times New Roman}\n\\setmonofont{Courier New}\n"},"include-before-body":{"text":"\\begin{titlepage}\n\\begin{center}\n\\vspace*{1cm}\n\n{\\Huge \\textbf{Kvantitativ metode og statistikk (IDR4000)}}\n\n\\vspace{1cm}\n{\\Large Kandidatnummer: 505}\n\n\\vspace{1cm}\nAntall ord: \\textbf{12874} % Setter inn ordtellingen her\n\n\\vspace{5cm}\n\\includegraphics[width=1.6\\textwidth]{logo.png}\n\n\\vfill\n{\\large 2024-11-22}\n\n\\end{center}\n\\end{titlepage}\n"},"output-file":"03-statistical-inference.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"block-headings":true,"bibliography":["resources/bib-final.bib"],"csl":"apa-numeric-superscript.csl","geometry":["top=0.5in","bottom=0.5in","left=1in","right=1in"],"latex_engine":"xelatex","mainfont":"Times New Roman","sansfont":"Times New Roman","monofont":"Courier New","title":"Å trekke slutninger fra statistiske modeller og statistisk styrke","editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["pdf"]}